{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-class Classification\n",
    "\n",
    "We want to assess the performance of a NN trained with a privacy engine based on SGD algorithm.\n",
    "The dataset is public and references to its license could be found in the README.md in /data subdirectory of the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the entry point of our spark app\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"2-class classification\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to download the dataset\n",
    "\n",
    "The dataset we use can downloaded from https://raw.githubusercontent.com/alessio-proietti/dp-sgd-notebook/main/data/bank-additional-full-new-label.csv. \n",
    "\n",
    "It's shipped with the repo itself though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: long (nullable = true)\n",
      " |-- campaign: long (nullable = true)\n",
      " |-- pdays: long (nullable = true)\n",
      " |-- previous: long (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- emp_var_rate: double (nullable = true)\n",
      " |-- cons_price_idx: double (nullable = true)\n",
      " |-- con_conf_idx: double (nullable = true)\n",
      " |-- euribor3m: double (nullable = true)\n",
      " |-- nr_employed: double (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = spark.createDataFrame(pd.read_csv(\"data/bank-additional-full-new-label.csv\"))\n",
    "df.printSchema()\n",
    "#df.show(n=2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = [field for (field, dataType) in df.dtypes if ( dataType != \"string\" )]\n",
    "categoricalCols = [field for (field, dataType) in df.dtypes if (dataType == \"string\" and field != \"y\")]\n",
    "\n",
    "indexOutputCols = [x + \"Index\" for x in categoricalCols]\n",
    "oheOutputCols = [x + \"OHE\" for x in categoricalCols]\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=indexOutputCols, handleInvalid=\"skip\")\n",
    "oheEncoder = OneHotEncoder(inputCols=indexOutputCols, outputCols=oheOutputCols)\n",
    "\n",
    "assemblerInputs = oheOutputCols + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "stringIndexerLabel = StringIndexer(inputCol=\"y\", outputCol=\"label\", handleInvalid=\"skip\")\n",
    "labelModel = stringIndexerLabel.fit(df)\n",
    "df = labelModel.transform(df)\n",
    "\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|label|            features|prediction|\n",
      "+-----+--------------------+----------+\n",
      "|  0.0|(53,[6,12,15,21,2...|       0.0|\n",
      "|  0.0|(53,[6,12,15,21,2...|       0.0|\n",
      "|  0.0|(53,[6,12,15,21,2...|       0.0|\n",
      "|  0.0|(53,[6,12,15,21,2...|       0.0|\n",
      "|  0.0|(53,[0,12,16,21,2...|       0.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = df.randomSplit([3.0, 1.0, 1.0], 24)\n",
    "\n",
    "pipeline = Pipeline(stages=[stringIndexer, oheEncoder, vecAssembler, lr])\n",
    "pipelineModel = pipeline.fit(train)\n",
    "predDF = pipelineModel.transform(train).select(\"label\",\"features\",\"prediction\")\n",
    "predDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6805911374869664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "areaUnderROC = evaluator.evaluate(predDF)\n",
    "areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

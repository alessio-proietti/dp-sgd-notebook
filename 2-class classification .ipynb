{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-class Classification\n",
    "\n",
    "The dataset is public and references to its license could be found in the README.md in /data subdirectory of the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon import nn, Trainer\n",
    "from mxnet.gluon.data import DataLoader, ArrayDataset\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the entry point of our spark app\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"2-class classification\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to download the dataset\n",
    "\n",
    "The dataset we use can downloaded from https://raw.githubusercontent.com/alessio-proietti/dp-sgd-notebook/main/data/bank-additional-full-new-label.csv. \n",
    "\n",
    "It's shipped with the repo itself though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: long (nullable = true)\n",
      " |-- campaign: long (nullable = true)\n",
      " |-- pdays: long (nullable = true)\n",
      " |-- previous: long (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- emp_var_rate: double (nullable = true)\n",
      " |-- cons_price_idx: double (nullable = true)\n",
      " |-- con_conf_idx: double (nullable = true)\n",
      " |-- euribor3m: double (nullable = true)\n",
      " |-- nr_employed: double (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n",
      "-RECORD 0---------------------\n",
      " age            | 56          \n",
      " job            | housemaid   \n",
      " marital        | married     \n",
      " education      | basic.4y    \n",
      " default        | no          \n",
      " housing        | no          \n",
      " loan           | no          \n",
      " contact        | telephone   \n",
      " month          | may         \n",
      " day_of_week    | mon         \n",
      " duration       | 261         \n",
      " campaign       | 1           \n",
      " pdays          | 999         \n",
      " previous       | 0           \n",
      " poutcome       | nonexistent \n",
      " emp_var_rate   | 1.1         \n",
      " cons_price_idx | 93994.0     \n",
      " con_conf_idx   | -36.4       \n",
      " euribor3m      | 4857.0      \n",
      " nr_employed    | 5191.0      \n",
      " y              | no          \n",
      "-RECORD 1---------------------\n",
      " age            | 57          \n",
      " job            | services    \n",
      " marital        | married     \n",
      " education      | high.school \n",
      " default        | unknown     \n",
      " housing        | no          \n",
      " loan           | no          \n",
      " contact        | telephone   \n",
      " month          | may         \n",
      " day_of_week    | mon         \n",
      " duration       | 149         \n",
      " campaign       | 1           \n",
      " pdays          | 999         \n",
      " previous       | 0           \n",
      " poutcome       | nonexistent \n",
      " emp_var_rate   | 1.1         \n",
      " cons_price_idx | 93994.0     \n",
      " con_conf_idx   | -36.4       \n",
      " euribor3m      | 4857.0      \n",
      " nr_employed    | 5191.0      \n",
      " y              | no          \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(pd.read_csv(\"data/bank-additional-full-new-label.csv\"))\n",
    "df.printSchema()\n",
    "df.show(n=2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = [field for (field, dataType) in df.dtypes if ( dataType != \"string\" )]\n",
    "categoricalCols = [field for (field, dataType) in df.dtypes if (dataType == \"string\" and field != \"y\")]\n",
    "\n",
    "indexOutputCols = [x + \"Index\" for x in categoricalCols]\n",
    "oheOutputCols = [x + \"OHE\" for x in categoricalCols]\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=indexOutputCols, handleInvalid=\"skip\")\n",
    "oheEncoder = OneHotEncoder(inputCols=indexOutputCols, outputCols=oheOutputCols)\n",
    "\n",
    "assemblerInputs = oheOutputCols + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "stringIndexerLabel = StringIndexer(inputCol=\"y\", outputCol=\"label\", handleInvalid=\"skip\")\n",
    "labelModel = stringIndexerLabel.fit(df)\n",
    "df = labelModel.transform(df)\n",
    "\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|label|            features|prediction|\n",
      "+-----+--------------------+----------+\n",
      "|  0.0|(53,[6,12,15,21,2...|       0.0|\n",
      "|  0.0|(53,[6,12,15,21,2...|       0.0|\n",
      "|  0.0|(53,[6,12,15,21,2...|       0.0|\n",
      "|  0.0|(53,[6,12,15,21,2...|       0.0|\n",
      "|  0.0|(53,[0,12,16,21,2...|       0.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = df.randomSplit([3.0, 1.0, 1.0], 24)\n",
    "\n",
    "pipeline = Pipeline(stages=[stringIndexer, oheEncoder, vecAssembler, lr])\n",
    "pipelineModel = pipeline.fit(train)\n",
    "predDF = pipelineModel.transform(train).select(\"label\",\"features\",\"prediction\")\n",
    "predDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6804999257388932"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "areaUnderROC = evaluator.evaluate(predDF)\n",
    "areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.0000e+00  0.0000e+00  0.0000e+00 ... -3.6400e+01  4.8550e+03\n",
       "   5.1910e+03]\n",
       " [ 0.0000e+00  0.0000e+00  0.0000e+00 ... -3.6400e+01  4.8550e+03\n",
       "   5.1910e+03]\n",
       " [ 0.0000e+00  0.0000e+00  0.0000e+00 ... -3.6400e+01  4.8550e+03\n",
       "   5.1910e+03]\n",
       " ...\n",
       " [ 0.0000e+00  0.0000e+00  0.0000e+00 ... -3.8300e+01  9.0300e+02\n",
       "   4.9916e+03]\n",
       " [ 0.0000e+00  0.0000e+00  0.0000e+00 ... -3.0100e+01  7.1600e+02\n",
       "   5.0175e+03]\n",
       " [ 0.0000e+00  0.0000e+00  0.0000e+00 ... -2.6900e+01  7.3000e-01\n",
       "   5.0175e+03]]\n",
       "<NDArray 24748x53 @cpu(0)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.array([row.features.toArray() for row in predDF.collect()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection\n",
    "\n",
    "The dataset is public and references to its license could be found in the README.md in /data subdirectory of the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd, np, npx, gluon, optimizer, init\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the entry point of our spark app\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"2-class classification\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to download the dataset\n",
    "\n",
    "The dataset we use can downloaded from https://raw.githubusercontent.com/alessio-proietti/dp-sgd-notebook/main/data/bank-additional-full-new-label.csv. \n",
    "\n",
    "It's shipped with the repo itself though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd.read_csv(\"data/bank-additional-full-new-label.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx', 'con_conf_idx', 'euribor3m', 'nr_employed', 'y']\n",
      "+-------+------------------+-----------------+------------------+-------------------+\n",
      "|summary|               age|         campaign|             pdays|           previous|\n",
      "+-------+------------------+-----------------+------------------+-------------------+\n",
      "|  count|             41188|            41188|             41188|              41188|\n",
      "|   mean| 40.02406040594348|2.567592502670681| 962.4754540157328|0.17296299893172767|\n",
      "| stddev|10.421249980934048|2.770013542902328|186.91090734474213| 0.4949010798392895|\n",
      "|    min|                17|                1|                 0|                  0|\n",
      "|    max|                98|               56|               999|                  7|\n",
      "+-------+------------------+-----------------+------------------+-------------------+\n",
      "\n",
      "+-------+-------------------+-----------------+------------------+------------------+-----------------+\n",
      "|summary|       emp_var_rate|   cons_price_idx|      con_conf_idx|         euribor3m|      nr_employed|\n",
      "+-------+-------------------+-----------------+------------------+------------------+-----------------+\n",
      "|  count|              41188|            41188|             41188|             41188|            41188|\n",
      "|   mean|0.08188550063118286|85401.57995532575|-40.50260027192253|3248.3071241623943|5167.035910945536|\n",
      "| stddev| 1.5709597405170252| 26471.5067956903| 4.628197856174539|1992.6134355948668|72.25152766825497|\n",
      "|    min|               -3.4|             93.2|             -50.8|              0.64|           4963.6|\n",
      "|    max|                1.4|          94767.0|             -26.9|            5045.0|           5228.1|\n",
      "+-------+-------------------+-----------------+------------------+------------------+-----------------+\n",
      "\n",
      "yes: 4640\n",
      "no: 36548\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.drop('duration')\n",
    "df.describe(['age', 'campaign', 'pdays', 'previous']).show()\n",
    "df.describe(['emp_var_rate', 'cons_price_idx', 'con_conf_idx', 'euribor3m', \"nr_employed\"]).show()\n",
    "print('yes:', df.filter(df['y'] == 'yes').count())\n",
    "print('no:', df.filter(df['y'] == 'no').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we set the stages for data processing\n",
    "\n",
    "numericCols = [field for (field, dataType) in df.dtypes if ( dataType != \"string\" )]\n",
    "categoricalCols = [field for (field, dataType) in df.dtypes if (dataType == \"string\" and field != \"y\")]\n",
    "\n",
    "indexOutputCols = [x + \"Index\" for x in categoricalCols]\n",
    "oheOutputCols = [x + \"OHE\" for x in categoricalCols]\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=indexOutputCols, handleInvalid=\"skip\")\n",
    "oheEncoder = OneHotEncoder(inputCols=indexOutputCols, outputCols=oheOutputCols)\n",
    "\n",
    "assemblerInputs = oheOutputCols + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexerLabel = StringIndexer(inputCol=\"y\", outputCol=\"label\", handleInvalid=\"skip\")\n",
    "labelModel = stringIndexerLabel.fit(df)\n",
    "df = labelModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = df.randomSplit([.75, .25], 24)\n",
    "\n",
    "pipeline = Pipeline(stages=[stringIndexer, oheEncoder, vecAssembler])\n",
    "\n",
    "pipelineModel = pipeline.fit(train)\n",
    "train_df = pipelineModel.transform(train).select(\"label\",\"features\")\n",
    "\n",
    "pipelineModel = pipeline.fit(validation)\n",
    "val_df = pipelineModel.transform(validation).select(\"label\",\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy array costruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 500\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "npx.set_np()\n",
    "\n",
    "@optimizer.Optimizer.register\n",
    "class PrivateSGD(optimizer.Optimizer):\n",
    "    \n",
    "    def __init__(self, learning_rate=0.1, momentum=0.0, use_fused_step=False, **kwargs):\n",
    "        super(PrivateSGD, self).__init__(learning_rate=learning_rate, **kwargs)\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    def create_state(self, index, weight):\n",
    "        return None\n",
    "    \n",
    "    def step(self, indices, weights, grads, states):\n",
    "        for index, weight, grad, state in zip(indices, weights, grads, states):\n",
    "            self._update_count(index)\n",
    "            lr = self._get_lr(index)\n",
    "            wd = self._get_wd(index)\n",
    "\n",
    "            # preprocess grad\n",
    "            grad *= self.rescale_grad\n",
    "            if self.clip_gradient is not None:\n",
    "                grad = clip(grad, -self.clip_gradient, self.clip_gradient)\n",
    "            grad += wd * weight\n",
    "\n",
    "            # update mom\n",
    "            mom = state\n",
    "            if mom is not None:\n",
    "                mom[:] *= self.momentum\n",
    "                mom[:] -= lr * ( grad + sigma*np.random_normal(shape = grad.shape) )\n",
    "            else:\n",
    "                mom = -lr * ( grad + sigma*np.random_normal(shape = grad.shape) )\n",
    "\n",
    "            # update weight\n",
    "            weight[:] += mom\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'PrivateSGD', {'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
